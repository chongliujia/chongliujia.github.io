+++
title = 'RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„'
date = 2025-08-03T13:11:06+08:00
draft = false
+++

# RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„

## ç›®å½•
- [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
- [å¼‚æ­¥æ¶æ„è®¾è®¡](#å¼‚æ­¥æ¶æ„è®¾è®¡)
- [æ ¸å¿ƒç»„ä»¶è¯¦è§£](#æ ¸å¿ƒç»„ä»¶è¯¦è§£)
- [äº‹ä»¶å¾ªç¯ç®¡ç†æœºåˆ¶](#äº‹ä»¶å¾ªç¯ç®¡ç†æœºåˆ¶)
- [å‘é‡å­˜å‚¨å¼‚æ­¥ç­–ç•¥](#å‘é‡å­˜å‚¨å¼‚æ­¥ç­–ç•¥)
- [FastAPIé›†æˆæ¨¡å¼](#fastapié›†æˆæ¨¡å¼)
- [LangGraphå·¥ä½œæµè®¾è®¡](#langgraphå·¥ä½œæµè®¾è®¡)
- [å¼‚æ­¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¼‚æ­¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
- [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
  
---

## ç³»ç»Ÿæ¦‚è§ˆ

### æ•´ä½“æ¶æ„å›¾

![æ•´ä½“æ¶æ„å›¾.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/æ•´ä½“æ¶æ„å›¾.png)

### æŠ€æœ¯æ ˆ

- **Webæ¡†æ¶**: FastAPI (å¼‚æ­¥ASGI)
- **å¼‚æ­¥è¿è¡Œæ—¶**: Python asyncio
- **å‘é‡æ•°æ®åº“**: Milvus (æ”¯æŒå¼‚æ­¥æ“ä½œ)
- **LLMæ¡†æ¶**: LangChain + LangGraph
- **æ–‡æ¡£å¤„ç†**: LangChain Document Loaders + æ¨¡å—åŒ–åˆ†å—ç­–ç•¥
- **åµŒå…¥æ¨¡å‹**: DashScope Embeddings
- **åˆ†å—ç­–ç•¥**: é€’å½’ã€Tokenã€è¯­ä¹‰ã€å­—ç¬¦ã€ä»£ç ã€æ ¼å¼ç‰¹å®šç­–ç•¥

---

## å¼‚æ­¥æ¶æ„è®¾è®¡

### åˆ†å±‚å¼‚æ­¥æ¶æ„

![åˆ†å±‚å¼‚æ­¥æ¶æ„.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/åˆ†å±‚å¼‚æ­¥æ¶æ„.png)

### å¼‚æ­¥è®¾è®¡åŸåˆ™

1. **éé˜»å¡I/O**: æ‰€æœ‰ç½‘ç»œå’Œç£ç›˜æ“ä½œéƒ½ä½¿ç”¨å¼‚æ­¥æ–¹å¼
2. **çº¿ç¨‹æ± å›é€€**: å¯¹äºä¸æ”¯æŒå¼‚æ­¥çš„æ“ä½œï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œ
3. **äº‹ä»¶å¾ªç¯éš”ç¦»**: é¿å…ä¸åŒäº‹ä»¶å¾ªç¯é—´çš„å†²çª
4. **å¹¶å‘æ§åˆ¶**: åˆç†é™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…èµ„æºè€—å°½
5. **é”™è¯¯éš”ç¦»**: å¼‚æ­¥æ“ä½œçš„é”™è¯¯ä¸å½±å“æ•´ä¸ªç³»ç»Ÿ

---

## æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. AsyncLoopManager - äº‹ä»¶å¾ªç¯ç®¡ç†å™¨

```python
# src/utils/async_utils.py
class AsyncLoopManager:
    """ç»Ÿä¸€çš„å¼‚æ­¥äº‹ä»¶å¾ªç¯ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._loop = None
            self._thread = None
            self._executor = ThreadPoolExecutor(max_workers=4)
            self._initialized = True

```

**è®¾è®¡ç‰¹ç‚¹**:
- **çº¿ç¨‹å®‰å…¨å•ä¾‹**: ç¡®ä¿å…¨å±€å”¯ä¸€å®ä¾‹
- **çº¿ç¨‹æ± ç®¡ç†**: å†…ç½®çº¿ç¨‹æ± æ‰§è¡Œå™¨
- **å¾ªç¯æ£€æµ‹**: æ™ºèƒ½æ£€æµ‹å½“å‰äº‹ä»¶å¾ªç¯çŠ¶æ€
- **å¼‚å¸¸éš”ç¦»**: å„ç§å¼‚æ­¥ä¸Šä¸‹æ–‡çš„å®‰å…¨å¤„ç†

### 2. VectorStoreManager - å‘é‡å­˜å‚¨ç®¡ç†å™¨

![å‘é‡å­˜å‚¨ç®¡ç†å™¨.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/å‘é‡å­˜å‚¨ç®¡ç†å™¨.png)

**å…³é”®ç‰¹æ€§**:
- **æ‰¹é‡å¤„ç†**: æ”¯æŒå¤§é‡æ–‡æ¡£çš„åˆ†æ‰¹å‘é‡åŒ–
- **å¤šå±‚å›é€€**: åŒæ­¥æ–¹æ³• â†’ å¼‚æ­¥æ–¹æ³• â†’ å®Œå…¨å¤±è´¥
- **çº¿ç¨‹æ± ä¼˜å…ˆ**: é¿å…äº‹ä»¶å¾ªç¯å†²çªçš„ç­–ç•¥
- **è¿›åº¦è·Ÿè¸ª**: å®æ—¶åé¦ˆå¤„ç†è¿›åº¦å’ŒæˆåŠŸç‡

### 3. KnowledgeBaseManager - çŸ¥è¯†åº“ç®¡ç†å™¨

å¢å¼ºçš„å¼‚æ­¥æ–¹æ³•ç¤ºä¾‹ï¼š

```python
async def add_file(self, file_path: Union[str, Path], 
                  chunking_strategy: str = None, 
                  strategy_params: Dict[str, Any] = None) -> Dict[str, Any]:
    """å¼‚æ­¥æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“ - æ”¯æŒç­–ç•¥é€‰æ‹©"""
    try:
        # 1. æ™ºèƒ½æ–‡æ¡£å¤„ç† (CPUå¯†é›†å‹) - æ”¯æŒç­–ç•¥é€‰æ‹©
        documents = self.doc_processor.process_file(
            file_path, 
            chunking_strategy=chunking_strategy,
            strategy_params=strategy_params
        )
        
        # 2. åŒæ­¥æ–‡æ¡£éªŒè¯
        valid_documents = DocumentValidator.validate_documents(documents)
        
        # 3. å¼‚æ­¥å‘é‡åŒ–å­˜å‚¨ (I/Oå¯†é›†å‹)
        result = await self.vector_manager.add_documents(valid_documents)
        
        # 4. åŒæ­¥å…ƒæ•°æ®ä¿å­˜ (åŒ…å«ç­–ç•¥ä¿¡æ¯)
        strategy_info = self.doc_processor.get_strategy_info()
        metadata = {
            "operation": "add_file",
            "file_path": str(file_path),
            "chunking_strategy": strategy_info.get("name"),
            "strategy_params": strategy_info.get("parameters", {}),
            "timestamp": datetime.now().isoformat(),
            "vector_result": result
        }
        self.save_processing_metadata(metadata)
        
        return result
    except Exception as e:
        # é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
        return error_result
```

**è®¾è®¡äº®ç‚¹**:
- **æ··åˆå¤„ç†**: CPUå¯†é›†å‹åŒæ­¥ï¼ŒI/Oå¯†é›†å‹å¼‚æ­¥
- **æ™ºèƒ½åˆ†å—**: æ”¯æŒå¤šç§åˆ†å—ç­–ç•¥å’Œè‡ªåŠ¨ç­–ç•¥é€‰æ‹©
- **å…ƒæ•°æ®ç®¡ç†**: å®Œæ•´çš„å¤„ç†å†å²è®°å½•å’Œç­–ç•¥è¿½è¸ª
- **ç»Ÿä¸€æœç´¢æ¥å£**: æ”¯æŒå¸¦åˆ†æ•°å’Œä¸å¸¦åˆ†æ•°çš„æœç´¢
- **æ–‡ä»¶æ›´æ–°æœºåˆ¶**: æ™ºèƒ½çš„å¢é‡æ›´æ–°ç­–ç•¥
- **ç­–ç•¥ä¼˜åŒ–**: æ ¹æ®æ–‡ä»¶ç±»å‹è‡ªåŠ¨æ¨èæœ€ä½³åˆ†å—ç­–ç•¥

---

## äº‹ä»¶å¾ªç¯ç®¡ç†æœºåˆ¶

### å¼‚æ­¥ä¸Šä¸‹æ–‡æ£€æµ‹æµç¨‹

![å¼‚æ­¥ä¸Šä¸‹æ–‡æ£€æµ‹æµç¨‹.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/å¼‚æ­¥ä¸Šä¸‹æ–‡æ£€æµ‹æµç¨‹.png)

### å…³é”®å‡½æ•°è¯¦è§£

```python
def is_async_context() -> bool:
    """æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­"""
    try:
        asyncio.get_running_loop()
        return True
    except RuntimeError:
        return False

async def run_in_thread_pool(func: Callable, *args, **kwargs) -> Any:
    """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°"""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, functools.partial(func, *args, **kwargs))

def safe_async_run(coro: Coroutine) -> Any:
    """å®‰å…¨è¿è¡Œå¼‚æ­¥å‡½æ•°"""
    manager = AsyncLoopManager()
    return manager.run_sync(coro)
```

---

## å‘é‡å­˜å‚¨å¼‚æ­¥ç­–ç•¥

### å¼‚æ­¥æ“ä½œç­–ç•¥å›¾

![å¼‚æ­¥æ“ä½œç­–ç•¥å›¾.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/å¼‚æ­¥æ“ä½œç­–ç•¥å›¾.png)

### æ ¸å¿ƒä»£ç ç¤ºä¾‹

```python
async def _add_batch_isolated(self, batch: List[Document]) -> bool:
    """ä¼˜å…ˆä½¿ç”¨åŒæ­¥æ–¹æ³•é¿å…äº‹ä»¶å¾ªç¯å†²çª"""
    try:
        # ä¼˜å…ˆç­–ç•¥ï¼šçº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ–¹æ³•
        try:
            await run_in_thread_pool(self.vector_store.add_documents, batch)
            return True
        except Exception as sync_e:
            print(f"åŒæ­¥æ–¹æ³•æ‰§è¡Œå¤±è´¥: {sync_e}")
            
            # å›é€€ç­–ç•¥ï¼šå½“å‰å¾ªç¯ä¸­æ‰§è¡Œå¼‚æ­¥æ–¹æ³•
            if hasattr(self.vector_store, 'aadd_documents'):
                try:
                    await self.vector_store.aadd_documents(batch)
                    return True
                except Exception as async_e:
                    print(f"å¼‚æ­¥æ–¹æ³•ä¹Ÿå¤±è´¥: {async_e}")
                    return False
            else:
                return False
        
    except Exception as e:
        print(f"æ‰¹æ¬¡æ·»åŠ å®Œå…¨å¤±è´¥: {e}")
        return False
```

**ç­–ç•¥ä¼˜åŠ¿**:
1. **çº¿ç¨‹æ± ä¼˜å…ˆ**: é¿å…gRPCå¼‚æ­¥å®¢æˆ·ç«¯çš„äº‹ä»¶å¾ªç¯å†²çª
2. **æ™ºèƒ½å›é€€**: å¤šå±‚å¼‚æ­¥/åŒæ­¥å›é€€æœºåˆ¶
3. **é”™è¯¯éš”ç¦»**: å•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¸å½±å“æ•´ä½“å¤„ç†
4. **è¯¦ç»†åé¦ˆ**: å®æ—¶è¿›åº¦å’Œé”™è¯¯ä¿¡æ¯

--- 

## FastAPIé›†æˆæ¨¡å¼

### å¼‚æ­¥ä¸­é—´ä»¶æ ˆ

![å¼‚æ­¥ä¸­é—´ä»¶æ ˆ.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/å¼‚æ­¥ä¸­é—´ä»¶æ ˆ.png)

### å¼‚æ­¥ç«¯ç‚¹ç¤ºä¾‹

```python
@router.post("/upload-file")
async def upload_file(file: UploadFile = File(...)):
    """å¼‚æ­¥æ–‡ä»¶ä¸Šä¼ å¤„ç†"""
    try:
        # 1. å¼‚æ­¥è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # 2. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ (åŒæ­¥æ“ä½œ)
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_path.suffix) as tmp_file:
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        try:
            # 3. å¼‚æ­¥å¤„ç†æ–‡ä»¶
            result = await knowledge_base_manager.add_file(tmp_file_path)
            result["original_filename"] = file.filename
            return result
            
        finally:
            # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_file_path)
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")
```

### æ¨¡å‹åˆå§‹åŒ–ä¸­é—´ä»¶

```python
@app.middleware("http")
async def initialize_models(request: Request, call_next):
    """ç¡®ä¿LangChainæ¨¡å‹å·²åˆå§‹åŒ–çš„å¼‚æ­¥ä¸­é—´ä»¶"""
    try:
        if not hasattr(app.state, "models_initialized"):
            logger.info("Initializing LangChain models...")
            
            # å¼‚æ­¥åˆå§‹åŒ–æ¨¡å‹
            chat_model = model_config.get_chat_model()
            embedding_model = model_config.get_embedding_model()
            vector_store = model_config.get_vector_store()
            
            app.state.chat_model = chat_model
            app.state.embedding_model = embedding_model
            app.state.vector_store = vector_store
            app.state.models_initialized = True
            
            logger.info("LangChain models initialized successfully")
        
        response = await call_next(request)
        return response
    except Exception as e:
        logger.error(f"Model initialization error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Model initialization failed"}
        )
```

--- 


## LangGraph å·¥ä½œæµè®¾è®¡

### RAGå¼‚æ­¥å·¥ä½œæµå›¾

![RAGå¼‚æ­¥å·¥ä½œæµ.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/RAGå¼‚æ­¥å·¥ä½œæµ.png)

### å¼‚æ­¥èŠ‚ç‚¹å®ç°

```python
async def retrieve_knowledge(self, state: RAGState) -> RAGState:
    """å¼‚æ­¥çŸ¥è¯†åº“æ£€ç´¢èŠ‚ç‚¹"""
    try:
        # ä½¿ç”¨å‘é‡å­˜å‚¨è¿›è¡Œå¼‚æ­¥æ£€ç´¢
        docs = await self.vector_store.asimilarity_search(
            state.query, k=5
        )
        state.documents.extend(docs)
        state.metadata["knowledge_retrieved"] = len(docs)
        
        # å¦‚æœç­–ç•¥æ˜¯bothï¼Œç»§ç»­æ‰§è¡Œwebæœç´¢
        if state.metadata.get("retrieval_strategy") == "both":
            return await self.search_web(state)
        
    except Exception as e:
        state.metadata["knowledge_error"] = str(e)
    
    return state

async def generate_response(self, state: RAGState) -> RAGState:
    """å¼‚æ­¥å›ç­”ç”ŸæˆèŠ‚ç‚¹"""
    try:
        # æ„å»ºæç¤ºè¯
        prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
        
ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{state.context}

ç”¨æˆ·é—®é¢˜ï¼š{state.query}

è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ï¼Œå¹¶åœ¨é€‚å½“æ—¶å¼•ç”¨æ¥æºã€‚"""

        # ä½¿ç”¨èŠå¤©æ¨¡å‹å¼‚æ­¥ç”Ÿæˆå›ç­”
        messages = [HumanMessage(content=prompt)]
        response = await self.chat_model.ainvoke(messages)
        
        state.response = response.content
        state.messages.append(HumanMessage(content=state.query))
        state.messages.append(AIMessage(content=response.content))
        
    except Exception as e:
        state.response = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
        state.metadata["generation_error"] = str(e)
    
    return state
```

### å·¥ä½œæµçŠ¶æ€ç®¡ç†

```python
class RAGState(BaseModel):
    """RAGå·¥ä½œæµçŠ¶æ€ - æ”¯æŒå¼‚æ­¥æ“ä½œ"""
    query: str
    messages: List[BaseMessage] = []
    documents: List[Document] = []
    web_results: List[Dict[str, Any]] = []
    context: str = ""
    response: str = ""
    metadata: Dict[str, Any] = {}
    
    class Config:
        arbitrary_types_allowed = True  # å…è®¸å¤æ‚ç±»å‹
```

**ç‰¹æ€§**:
- **çŠ¶æ€æŒä¹…åŒ–**: æ•´ä¸ªå·¥ä½œæµç¨‹ä¸­ä¿æŒçŠ¶æ€
- **å¼‚æ­¥èŠ‚ç‚¹**: æ”¯æŒå¼‚æ­¥æ“ä½œçš„èŠ‚ç‚¹
- **æ¡ä»¶è·¯ç”±**: åŸºäºçŠ¶æ€çš„æ™ºèƒ½è·¯ç”±
- **å…ƒæ•°æ®è·Ÿè¸ª**: è¯¦ç»†çš„æ‰§è¡Œå…ƒæ•°æ®

---

## å¼‚æ­¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜åˆ†æå›¾

![é—®é¢˜åˆ†æå›¾.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/é—®é¢˜åˆ†æå›¾.png)

### å…·ä½“é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

#### 1. äº‹ä»¶å¾ªç¯å†²çªé—®é¢˜

**é—®é¢˜ç°è±¡**:

```
RuntimeError: Task got Future attached to a different loop
```

**æ ¹æœ¬åŸå› **:
- Milvusçš„gRPCå¼‚æ­¥å®¢æˆ·ç«¯åœ¨ä¸åŒäº‹ä»¶å¾ªç¯é—´å…±äº«
- éš”ç¦»äº‹ä»¶å¾ªç¯ç­–ç•¥åˆ›å»ºäº†è·¨å¾ªç¯çš„Futureå¼•ç”¨

**è§£å†³æ–¹æ¡ˆ**:
```python
# åŸå§‹é—®é¢˜ä»£ç 
async def old_approach():
    # åœ¨éš”ç¦»å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥æ–¹æ³•
    return await run_in_isolated_loop_async(vector_store.aadd_documents(docs))

# ä¿®å¤åçš„ä»£ç   
async def new_approach():
    # ä¼˜å…ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•
    try:
        return await run_in_thread_pool(vector_store.add_documents, docs)
    except Exception:
        # å›é€€åˆ°å½“å‰å¾ªç¯çš„å¼‚æ­¥æ–¹æ³•
        return await vector_store.aadd_documents(docs)
```

#### 2. å¹¶å‘æ§åˆ¶é—®é¢˜

**è§£å†³æ–¹æ¡ˆ - ä¿¡å·é‡æ§åˆ¶**:

```python
import asyncio

class ConcurrencyController:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def execute_with_limit(self, coro):
        async with self.semaphore:
            return await coro
```

#### 3. é”™è¯¯å¤„ç†ä¸ç›‘æ§

**è§£å†³æ–¹æ¡ˆ - å¼‚æ­¥å¼‚å¸¸åŒ…è£…å™¨**:

```python
import functools
import logging

def async_error_handler(logger: logging.Logger):
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                logger.error(f"Async operation failed in {func.__name__}: {e}", 
                           exc_info=True)
                raise
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@async_error_handler(logger)
async def risky_async_operation():
    # å¯èƒ½å‡ºé”™çš„å¼‚æ­¥æ“ä½œ
    pass
```

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡å›¾

![æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡å›¾.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡å›¾.png)

### å…·ä½“ä¼˜åŒ–æªæ–½

#### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python 
class OptimizedVectorManager:
    def __init__(self, batch_size: int = 100, max_concurrent: int = 5):
        self.batch_size = batch_size
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def optimized_batch_add(self, documents: List[Document]):
        """ä¼˜åŒ–çš„æ‰¹é‡æ·»åŠ  - å¹¶å‘æ§åˆ¶ + æ‰¹é‡å¤„ç†"""
        batches = [documents[i:i + self.batch_size] 
                  for i in range(0, len(documents), self.batch_size)]
        
        async def process_batch(batch):
            async with self.semaphore:
                return await self._add_batch_isolated(batch)
        
        # å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¹æ¬¡
        results = await asyncio.gather(
            *[process_batch(batch) for batch in batches],
            return_exceptions=True
        )
        
        return self._aggregate_results(results)
```

#### 2. è¿æ¥æ± ä¼˜åŒ–

```python
from langchain_milvus import Milvus
import asyncio

class OptimizedMilvusManager:
    def __init__(self):
        self.connection_pool = asyncio.Queue(maxsize=10)
        self._initialize_pool()
    
    async def _initialize_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        for _ in range(5):  # é¢„åˆ›å»º5ä¸ªè¿æ¥
            connection = await self._create_connection()
            await self.connection_pool.put(connection)
    
    async def get_connection(self):
        """è·å–è¿æ¥"""
        return await self.connection_pool.get()
    
    async def return_connection(self, connection):
        """å½’è¿˜è¿æ¥"""
        await self.connection_pool.put(connection)
```

#### 3. å†…å­˜ä¼˜åŒ–ç­–ç•¥

```python
import gc
import psutil
from typing import AsyncGenerator

class MemoryOptimizedProcessor:
    def __init__(self, memory_threshold: float = 0.8):
        self.memory_threshold = memory_threshold
    
    async def process_large_dataset(self, documents: List[Document]) -> AsyncGenerator:
        """å†…å­˜ä¼˜åŒ–çš„å¤§æ•°æ®é›†å¤„ç†"""
        for i, doc in enumerate(documents):
            # å¤„ç†æ–‡æ¡£
            processed_doc = await self.process_document(doc)
            yield processed_doc
            
            # å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨
            if i % 100 == 0:
                memory_percent = psutil.virtual_memory().percent / 100
                if memory_percent > self.memory_threshold:
                    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
                    await asyncio.sleep(0.1)  # è®©å‡ºæ§åˆ¶æƒ
```

---

## ğŸ“‹ æœ€ä½³å®è·µ

### å¼‚æ­¥å¼€å‘æœ€ä½³å®è·µæ£€æŸ¥æ¸…å•

#### è®¾è®¡åŸåˆ™
- **å•ä¸€èŒè´£**: æ¯ä¸ªå¼‚æ­¥å‡½æ•°åªè´Ÿè´£ä¸€ä¸ªæ˜ç¡®çš„ä»»åŠ¡
- **éé˜»å¡ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨å¼‚æ­¥I/Oï¼Œé¿å…é˜»å¡æ“ä½œ
- **é”™è¯¯éš”ç¦»**: å¼‚æ­¥æ“ä½œçš„é”™è¯¯ä¸åº”å½±å“å…¶ä»–æ“ä½œ
- **èµ„æºç®¡ç†**: æ­£ç¡®ç®¡ç†è¿æ¥ã€æ–‡ä»¶å¥æŸ„ç­‰èµ„æº

#### ç¼–ç è§„èŒƒ
- **å‘½åè§„èŒƒ**: å¼‚æ­¥å‡½æ•°ä½¿ç”¨`async def`ï¼Œæ¸…æ™°çš„å‡½æ•°å‘½å
- **ç±»å‹æ³¨è§£**: ä½¿ç”¨ç±»å‹æç¤ºï¼Œç‰¹åˆ«æ˜¯`Coroutine`å’Œ`Awaitable`
- **å¼‚å¸¸å¤„ç†**: æ¯ä¸ªå¼‚æ­¥æ“ä½œéƒ½è¦æœ‰é€‚å½“çš„å¼‚å¸¸å¤„ç†
- **æ—¥å¿—è®°å½•**: å…³é”®å¼‚æ­¥æ“ä½œè¦æœ‰æ—¥å¿—è®°å½•

#### æ€§èƒ½è€ƒè™‘
- **å¹¶å‘æ§åˆ¶**: ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡
- **æ‰¹é‡å¤„ç†**: åˆå¹¶å°æ“ä½œä¸ºæ‰¹é‡æ“ä½œ
- **è¿æ¥å¤ç”¨**: ä½¿ç”¨è¿æ¥æ± é¿å…é¢‘ç¹åˆ›å»ºè¿æ¥
- **å†…å­˜ç®¡ç†**: å¤§æ•°æ®é‡å¤„ç†æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨

#### æµ‹è¯•ç­–ç•¥
- **å•å…ƒæµ‹è¯•**: ä½¿ç”¨`pytest-asyncio`è¿›è¡Œå¼‚æ­¥æµ‹è¯•
- **æ¨¡æ‹Ÿæµ‹è¯•**: æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–çš„å¼‚æ­¥æ“ä½œ
- **é›†æˆæµ‹è¯•**: æµ‹è¯•å®Œæ•´çš„å¼‚æ­¥å·¥ä½œæµ
- **æ€§èƒ½æµ‹è¯•**: æµ‹è¯•å¹¶å‘æ€§èƒ½å’Œèµ„æºä½¿ç”¨

### ä»£ç ç¤ºä¾‹ - å®Œæ•´çš„å¼‚æ­¥æœåŠ¡

```python
import asyncio
import logging
from typing import List, Dict, Any, Optional
from contextlib import asynccontextmanager

class AsyncRAGService:
    """å®Œæ•´çš„å¼‚æ­¥RAGæœåŠ¡ç¤ºä¾‹"""
    
    def __init__(self, max_concurrent: int = 10):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.session_pool = asyncio.Queue(maxsize=5)
        self._initialize_resources()
    
    async def _initialize_resources(self):
        """åˆå§‹åŒ–èµ„æº"""
        self.logger.info("Initializing async RAG service...")
        # åˆå§‹åŒ–è¿æ¥æ± ã€æ¨¡å‹ç­‰
    
    @asynccontextmanager
    async def get_session(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ä¼šè¯ç®¡ç†"""
        session = await self.session_pool.get()
        try:
            yield session
        finally:
            await self.session_pool.put(session)
    
    async def process_query(self, query: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢çš„å®Œæ•´å¼‚æ­¥æµç¨‹"""
        async with self.semaphore:  # å¹¶å‘æ§åˆ¶
            try:
                # 1. æŸ¥è¯¢åˆ†æ (å¼‚æ­¥)
                analysis = await self._analyze_query(query)
                
                # 2. æ–‡æ¡£æ£€ç´¢ (å¼‚æ­¥)
                documents = await self._retrieve_documents(query, analysis)
                
                # 3. å›ç­”ç”Ÿæˆ (å¼‚æ­¥)
                response = await self._generate_response(query, documents)
                
                return {
                    "success": True,
                    "query": query,
                    "response": response,
                    "metadata": {
                        "analysis": analysis,
                        "document_count": len(documents)
                    }
                }
                
            except Exception as e:
                self.logger.error(f"Failed to process query: {e}", exc_info=True)
                return {
                    "success": False,
                    "error": str(e),
                    "query": query
                }
    
    async def _analyze_query(self, query: str) -> Dict[str, Any]:
        """å¼‚æ­¥æŸ¥è¯¢åˆ†æ"""
        async with self.get_session() as session:
            # æ¨¡æ‹Ÿå¼‚æ­¥åˆ†æ
            await asyncio.sleep(0.1)
            return {"intent": "search", "complexity": "medium"}
    
    async def _retrieve_documents(self, query: str, analysis: Dict) -> List[Dict]:
        """å¼‚æ­¥æ–‡æ¡£æ£€ç´¢"""
        async with self.get_session() as session:
            # æ¨¡æ‹Ÿå¼‚æ­¥æ£€ç´¢
            await asyncio.sleep(0.2)
            return []
    
    async def _generate_response(self, query: str, documents: List) -> str:
        """å¼‚æ­¥å›ç­”ç”Ÿæˆ"""
        async with self.get_session() as session:
            # æ¨¡æ‹Ÿå¼‚æ­¥ç”Ÿæˆ
            await asyncio.sleep(0.3)
            return f"åŸºäº{len(documents)}ä¸ªæ–‡æ¡£çš„å›ç­”"
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("Cleaning up async RAG service...")
        # æ¸…ç†è¿æ¥æ± ã€å…³é—­ä¼šè¯ç­‰

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    service = AsyncRAGService(max_concurrent=5)
    
    # å¹¶å‘å¤„ç†å¤šä¸ªæŸ¥è¯¢
    queries = ["What is AI?", "How does ML work?", "Explain RAG"]
    results = await asyncio.gather(
        *[service.process_query(q) for q in queries],
        return_exceptions=True
    )
    
    for query, result in zip(queries, results):
        print(f"Query: {query}")
        print(f"Result: {result}")
        print("-" * 50)
    
    await service.cleanup()

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(main())
```

## åˆ†å—ç­–ç•¥æ¶æ„è¯¦è§£

### æ¨¡å—åŒ–åˆ†å—ç­–ç•¥ä½“ç³»

![æ¨¡å—åŒ–åˆ†å—ç­–ç•¥ä½“ç³».png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/æ¨¡å—åŒ–åˆ†å—ç­–ç•¥ä½“ç³».png)

### ç­–ç•¥é€‰æ‹©æµç¨‹

![ç­–ç•¥é€‰æ‹©æµç¨‹.png](/images/RAGç³»ç»Ÿå¼‚æ­¥è®¾è®¡æ¶æ„/ç­–ç•¥é€‰æ‹©æµç¨‹.png)

### æ–°å¢CLIå‘½ä»¤ç¤ºä¾‹

```bash
# åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç­–ç•¥
python scripts/knowledge_base_cli.py list-strategies

# è·å–ç­–ç•¥æ¨è
python scripts/knowledge_base_cli.py recommend-strategy --file-type pdf
python scripts/knowledge_base_cli.py recommend-strategy --use-case knowledge_base

# ä½¿ç”¨ç‰¹å®šç­–ç•¥æ·»åŠ æ–‡ä»¶
python scripts/knowledge_base_cli.py add-file document.pdf --strategy format --format-type pdf
python scripts/knowledge_base_cli.py add-file script.py --strategy code --language python

# ç›®å½•å¤„ç†æ”¯æŒè‡ªåŠ¨ç­–ç•¥é€‰æ‹©
python scripts/knowledge_base_cli.py add-dir docs/ # è‡ªåŠ¨æ¨¡å¼
python scripts/knowledge_base_cli.py add-dir docs/ --no-auto-strategy --strategy recursive

# åˆ›å»ºçŸ¥è¯†åº“æ—¶æŒ‡å®šé»˜è®¤ç­–ç•¥
python scripts/knowledge_base_cli.py create-kb research_papers --strategy semantic
```

---

## æ€»ç»“

æœ¬RAGç³»ç»Ÿçš„å¼‚æ­¥è®¾è®¡å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

### æ ¸å¿ƒä¼˜åŠ¿
1. **ç»Ÿä¸€ç®¡ç†**: `AsyncLoopManager`æä¾›ç»Ÿä¸€çš„äº‹ä»¶å¾ªç¯ç®¡ç†
2. **æ™ºèƒ½åˆ†å—**: æ¨¡å—åŒ–åˆ†å—ç­–ç•¥æ”¯æŒå¤šç§æ–‡æ¡£ç±»å‹ä¼˜åŒ–
3. **é”™è¯¯å®¹é”™**: å¤šå±‚å›é€€æœºåˆ¶ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
4. **é«˜æ€§èƒ½**: åˆç†çš„å¹¶å‘æ§åˆ¶å’Œæ‰¹é‡å¤„ç†
5. **æ˜“æ‰©å±•**: åŸºäºLangGraphçš„å·¥ä½œæµå’Œç­–ç•¥å·¥å‚æ¨¡å¼æ˜“äºæ‰©å±•

### è®¾è®¡äº®ç‚¹
1. **çº¿ç¨‹æ± ä¼˜å…ˆç­–ç•¥**: é¿å…gRPCå®¢æˆ·ç«¯çš„äº‹ä»¶å¾ªç¯å†²çª
2. **æ™ºèƒ½å›é€€æœºåˆ¶**: å¼‚æ­¥æ–¹æ³•å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°åŒæ­¥æ–¹æ³•
3. **æ¨¡å—åŒ–åˆ†å—æ¶æ„**: æ”¯æŒå¤šç§åˆ†å—ç­–ç•¥å’Œè‡ªåŠ¨ä¼˜åŒ–
4. **çŠ¶æ€é©±åŠ¨å·¥ä½œæµ**: LangGraphæä¾›çš„çŠ¶æ€æœºæ¨¡å¼
5. **å…¨æ ˆå¼‚æ­¥é›†æˆ**: ä»FastAPIåˆ°æ•°æ®åº“çš„ç«¯åˆ°ç«¯å¼‚æ­¥æ”¯æŒ
6. **æ ¼å¼æ„ŸçŸ¥å¤„ç†**: æ ¹æ®æ–‡ä»¶ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¤„ç†ç­–ç•¥

### æ€§èƒ½è¡¨ç°
- **å¹¶å‘å¤„ç†**: æ”¯æŒå¤§é‡å¹¶å‘æ–‡æ¡£å¤„ç†
- **æ™ºèƒ½ä¼˜åŒ–**: è‡ªåŠ¨ç­–ç•¥é€‰æ‹©æå‡å¤„ç†è´¨é‡
- **èµ„æºä¼˜åŒ–**: åˆç†çš„å†…å­˜å’Œè¿æ¥ç®¡ç†
- **å“åº”æ—¶é—´**: éé˜»å¡I/Oæ˜¾è‘—æå‡å“åº”é€Ÿåº¦
- **é”™è¯¯æ¢å¤**: å¿«é€Ÿçš„é”™è¯¯æ£€æµ‹å’Œæ¢å¤æœºåˆ¶

### æœ€æ–°åŠŸèƒ½
- **æ¨¡å—åŒ–åˆ†å—ç­–ç•¥**: 6ç§ä¸“ä¸šåˆ†å—ç­–ç•¥ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•
- **æ™ºèƒ½ç­–ç•¥æ¨è**: æ ¹æ®æ–‡ä»¶ç±»å‹å’Œä½¿ç”¨åœºæ™¯è‡ªåŠ¨æ¨èæœ€ä½³ç­–ç•¥
- **æ ¼å¼ç‰¹å®šä¼˜åŒ–**: é’ˆå¯¹PDFã€ä»£ç ã€Markdownç­‰æ ¼å¼çš„ä¸“é—¨ä¼˜åŒ–
- **å¢å¼ºCLIå·¥å…·**: å®Œæ•´çš„ç­–ç•¥ç®¡ç†å’Œé…ç½®å‘½ä»¤
- **è¯¦ç»†å…ƒæ•°æ®è¿½è¸ª**: è®°å½•åˆ†å—ç­–ç•¥ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½æŒ‡æ ‡

è¿™ä¸ªå¼‚æ­¥æ¶æ„ä¸ºRAGç³»ç»Ÿæä¾›äº†é«˜æ€§èƒ½ã€é«˜å¯é æ€§ã€é«˜æ™ºèƒ½åŒ–çš„åŸºç¡€è®¾æ–½ï¼Œæ”¯æŒå¤§è§„æ¨¡æ–‡æ¡£å¤„ç†å’Œå®æ—¶æŸ¥è¯¢å“åº”ã€‚
